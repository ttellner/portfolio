# Railway File Storage Guide

## Important: Ephemeral Filesystem

**⚠️ CRITICAL:** Railway uses an **ephemeral filesystem**. This means:

- ✅ Files **ARE saved** to the filesystem during runtime (in `pages/bankingprojects/data/`)
- ❌ Files **ARE LOST** when the container restarts or redeploys
- ❌ Files **ARE NOT persistent** across deployments
- ❌ Files **ARE NOT accessible** via SSH or file browser in Railway

## Where Files Are Saved

Files generated by the analysis pipeline are saved to:
```
pages/bankingprojects/data/
```

### Generated Files:

1. **Data Pipeline:**
   - `var_metadata_input.csv`

2. **Variable Metadata Analysis:**
   - `var_metadata_output.csv`
   - `feat_eng_data.csv`

3. **Feature Engineering Analysis:**
   - `feat_eng_output.csv`
   - `woe_ready.csv`

4. **IV/WoE Analysis:**
   - `iv_woe_output.csv` (equivalent to CREDIT.PD_IV_SUMMARY)
   - `woe_statistics.csv`
   - `woe_transformed_data.csv` (equivalent to CREDIT.PD_MODEL_DATA_CH10_CLEAN)
   - `model_data_filtered.csv` (equivalent to CREDIT.PD_MODEL_DATA_CH10_FILTERED)

## How to View Files on Railway

### Option 1: Download from Streamlit UI (Recommended)

The Streamlit app provides download buttons for output files:
- Each analysis page has download buttons in the sidebar
- Click the download button to download the file to your local machine
- Files are downloaded directly from the container filesystem

### Option 2: Railway CLI (Advanced)

1. **Install Railway CLI:**
   ```bash
   npm i -g @railway/cli
   ```

2. **Login:**
   ```bash
   railway login
   ```

3. **Connect to your project:**
   ```bash
   railway link
   ```

4. **Open a shell in the running container:**
   ```bash
   railway shell
   ```

5. **Navigate to data directory:**
   ```bash
   cd pages/bankingprojects/data
   ls -la
   ```

6. **Copy files locally (if needed):**
   ```bash
   # Files are in the container, but you can't directly copy them
   # Use the Streamlit download buttons instead
   ```

### Option 3: Add Download Endpoint (Custom Solution)

You could create a custom Streamlit page that lists and downloads all generated files:

```python
# pages/bankingprojects/download_files.py
import streamlit as st
from pathlib import Path
import os

st.title("Download Generated Files")

data_dir = Path(__file__).parent / "data"
files = list(data_dir.glob("*.csv"))

for file in files:
    if file.exists():
        with open(file, 'rb') as f:
            st.download_button(
                label=f"Download {file.name}",
                data=f.read(),
                file_name=file.name,
                mime="text/csv"
            )
```

## Making Files Persistent (If Needed)

If you need files to persist across deployments, you have several options:

### Option 1: Railway Volumes (Recommended for Persistence)

1. **Create a volume in Railway:**
   - Railway Dashboard → Your Project → Volumes
   - Create new volume: `data-storage`

2. **Mount the volume:**
   - Add to your `Dockerfile` or Railway settings:
   ```dockerfile
   VOLUME /app/pages/bankingprojects/data
   ```

3. **Mount in Railway:**
   - Settings → Volumes → Mount volume to `/app/pages/bankingprojects/data`

**Note:** Volumes add cost and complexity. For most use cases, the ephemeral filesystem is fine since users can download files via the UI.

### Option 2: External Storage (S3, etc.)

Modify the code to save files to S3 or another external storage service instead of local filesystem.

### Option 3: Database Storage

Store file contents in a database (PostgreSQL, etc.) instead of filesystem.

## Recommended Approach

**For your use case, the ephemeral filesystem is fine because:**

1. ✅ Users can download files via Streamlit UI
2. ✅ Files are generated on-demand during analysis
3. ✅ No need for long-term persistence
4. ✅ Simplest setup (no volumes needed)

**The download buttons in the Streamlit UI provide the best user experience** for accessing generated files.

## Feature Tracking Script

Use the `track_features.py` script to track features through the pipeline:

```bash
cd pages/bankingprojects
python track_features.py
```

This script:
- Reads all intermediate CSV files
- Shows feature counts at each stage
- Shows features added/removed between stages
- Provides a summary of the pipeline

**Run this script locally** (not on Railway) to analyze your pipeline flow.

## Summary

- **Files ARE saved** during runtime in `pages/bankingprojects/data/`
- **Files ARE LOST** on container restart/redeploy
- **Best way to access:** Use Streamlit download buttons
- **For persistence:** Use Railway volumes (if needed)
- **For analysis:** Run `track_features.py` locally

